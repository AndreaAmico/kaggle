{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import xgboost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "if os.name == 'posix':\n",
    "    %config InlineBackend.figure_format = 'retina' #retina display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Nulls</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>Cabin_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.539691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.905144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.319970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.220411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.812033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.060890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.795673</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked  Nulls  FamilySize  \\\n",
       "0       3    0 -0.539691      1      0 -0.905144         0      1           2   \n",
       "1       1    1  0.681592      1      0  1.319970         1      0           2   \n",
       "2       3    1 -0.220411      0      0 -0.812033         0      1           1   \n",
       "3       1    1  0.462678      1      0  1.060890         0      0           2   \n",
       "4       3    0  0.462678      0      0 -0.795673         0      1           1   \n",
       "\n",
       "   Title  Cabin_mapped  \n",
       "0      2             0  \n",
       "1      3             1  \n",
       "2      1             0  \n",
       "3      3             1  \n",
       "4      2             0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer='./train.csv')\n",
    "df_test = pd.read_csv(filepath_or_buffer='./test.csv')\n",
    "\n",
    "XX = pd.concat([df.drop('Survived', axis = 1), df_test], axis = 0)\n",
    "XX.drop('PassengerId', axis = 1, inplace=True)\n",
    "\n",
    "XX['Nulls'] = XX.Cabin.isnull().astype('int') + XX.Age.isnull().astype('int')\n",
    "XX['FamilySize'] = XX['SibSp'] + XX['Parch'] + 1\n",
    "\n",
    "import re\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "XX['Title'] = XX['Name'].apply(get_title)\n",
    "XX['Title'] = XX['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', \n",
    "                                             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "XX['Title'] = XX['Title'].replace('Mlle', 'Miss')\n",
    "XX['Title'] = XX['Title'].replace('Ms', 'Miss')\n",
    "XX['Title'] = XX['Title'].replace('Mme', 'Mrs')\n",
    "XX.drop(['Name'], inplace = True, axis = 1)\n",
    "label_title = preprocessing.LabelEncoder()\n",
    "label_title.fit(XX.Title)\n",
    "XX.Title = label_title.transform(XX.Title)\n",
    "\n",
    "\n",
    "XX['Cabin_mapped'] = XX['Cabin'].astype(str).str[0] # this captures the letter\n",
    "cabin_dict = {k:i for i, k in enumerate(XX.Cabin_mapped.unique())} \n",
    "XX.loc[:, 'Cabin_mapped'] = XX.loc[:, 'Cabin_mapped'].map(cabin_dict)\n",
    "XX.drop(['Cabin'], inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "XX['Fare'].fillna(XX.Fare.median(), inplace = True)\n",
    "scaler_box = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "scaler_box.fit(XX.Fare.values.reshape(-1, 1))\n",
    "XX.Fare = scaler_box.transform(XX.Fare.values.reshape(-1,1))\n",
    "\n",
    "XX['Age'].fillna(XX.Age.median(), inplace = True)\n",
    "scaler_box = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "scaler_box.fit(XX.Age.values.reshape(-1, 1))\n",
    "XX.Age = scaler_box.transform(XX.Age.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XX['Embarked'].fillna('S', inplace = True)\n",
    "XX['Embarked'] = XX['Embarked'].map( {'C': 1, 'S': 0, 'Q':2} ).astype(int)\n",
    "\n",
    "XX['Sex'] = XX['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "\n",
    "XX.drop(['Ticket'], inplace = True, axis = 1)\n",
    "# XX.drop(['Parch'], inplace = True, axis = 1)\n",
    "# XX.drop(['SibSp'], inplace = True, axis = 1)\n",
    "\n",
    "# X_dummies = pd.get_dummies(XX, columns = ['Title'], drop_first= True)\n",
    "\n",
    "\n",
    "# print(XX.columns)\n",
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XX[:len(df)];\n",
    "new_X = XX[len(df):]\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8236d41b5a24ce4b7d5b5ba4cac680b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8462979650590631\n",
      "Generation 2 - Current best internal CV score: 0.8462979650590631\n",
      "Generation 3 - Current best internal CV score: 0.8496562683635325\n",
      "Generation 4 - Current best internal CV score: 0.8496814475703307\n",
      "Generation 5 - Current best internal CV score: 0.8496814475703307\n",
      "Generation 6 - Current best internal CV score: 0.8496814475703307\n",
      "Generation 7 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 8 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 9 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 10 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 11 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 12 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 13 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 14 - Current best internal CV score: 0.8519034593747683\n",
      "Generation 15 - Current best internal CV score: 0.8552616208245517\n",
      "Generation 16 - Current best internal CV score: 0.8552616208245517\n",
      "Generation 17 - Current best internal CV score: 0.8552616208245517\n",
      "Generation 18 - Current best internal CV score: 0.8564167435341747\n",
      "Generation 19 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 20 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 21 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 22 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 23 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 24 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 25 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 26 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 27 - Current best internal CV score: 0.8597624217715735\n",
      "Generation 28 - Current best internal CV score: 0.8597624217715735\n",
      "\n",
      "50.003183416666666 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.1, max_depth=8, max_features=0.45, min_samples_leaf=19, min_samples_split=12, n_estimators=100, subsample=1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=1000000,\n",
       "        max_eval_time_mins=5, max_time_mins=50, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=100,\n",
       "        random_state=None, scoring=None, subsample=1.0, template=None,\n",
       "        use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(verbosity=2, max_time_mins=50)\n",
    "tpot.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = tpot.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225589225589226"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_predict==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_pipeline_2.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tpot_prediction = tpot.predict(new_X)\n",
    "submission = pd.concat([df_test.PassengerId, pd.DataFrame(y_tpot_prediction)], axis = 'columns')\n",
    "submission.columns = [\"PassengerId\", \"Survived\"]\n",
    "submission.to_csv('tpot_03.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aamico\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svm_prediction = clf.predict(new_X)\n",
    "submission = pd.concat([df_test.PassengerId, pd.DataFrame(y_svm_prediction)], axis = 'columns')\n",
    "submission.columns = [\"PassengerId\", \"Survived\"]\n",
    "submission.to_csv('svm_01.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aamico\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X, y)\n",
    "\n",
    "y_rfc_prediction = rfc.predict(new_X)\n",
    "submission = pd.concat([df_test.PassengerId, pd.DataFrame(y_rfc_prediction)], axis = 'columns')\n",
    "submission.columns = [\"PassengerId\", \"Survived\"]\n",
    "submission.to_csv('rfc_01.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge = RidgeClassifier()\n",
    "ridge.fit(X, y)\n",
    "\n",
    "y_ridge_prediction = ridge.predict(new_X)\n",
    "submission = pd.concat([df_test.PassengerId, pd.DataFrame(y_ridge_prediction)], axis = 'columns')\n",
    "submission.columns = [\"PassengerId\", \"Survived\"]\n",
    "submission.to_csv('ridge_01.csv', header=True, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ridge_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
