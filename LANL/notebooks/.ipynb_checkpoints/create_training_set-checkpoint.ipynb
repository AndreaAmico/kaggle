{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quake_in_chunk(chunk_df):\n",
    "    return np.sum(np.abs(np.diff(chunk_df.time_to_failure))>0.1)>0\n",
    "\n",
    "def progress_bar(current_value, max_value, size=50):\n",
    "    prog = (current_value+1)/max_value\n",
    "    left = '#'*int(prog * size + 0.5) # 0.5 to round up when casting to int\n",
    "    right = '-'*(size-len(left))\n",
    "    print('\\r[{}{}] {:.1f}%'.format(left, right, prog*100), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import argrelextrema\n",
    "\n",
    "# df_generator = pd.read_csv(f'{ROOT_PATH}/data/train.csv', chunksize=100000)\n",
    "# index_minima = []\n",
    "# for df in df_generator:\n",
    "#     index_minima.append(df.iloc[argrelextrema(df.time_to_failure.values, np.less_equal, order=2)[0]].index.tolist()[:-1])\n",
    "\n",
    "\n",
    "# from scipy.signal import argrelextrema\n",
    "# index_minima = df.iloc[argrelextrema(df.time_to_failure.values, np.less_equal, order=2)[0]].index.tolist()[:-1]\n",
    "# event_index = np.array([x[0] for x in index_minima if len(x)>0])\n",
    "# np.savetxt(f\"{ROOT_PATH}/data/event_index.csv\", event_index, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_index = np.genfromtxt(f\"{ROOT_PATH}/data/event_index.csv\", dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "event_index = array([  5656573,  50085877, 104677355, 138772452, 187641819, 218652629,\n",
    "       245829584, 307838916, 338276286, 375377847, 419368879, 461811622,\n",
    "       495800224, 528777114, 585568143, 621985672])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "test_df.shape = (150000, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split feature from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##################################################] 100.0%"
     ]
    }
   ],
   "source": [
    "resample_window_size = 15\n",
    "chunk_len = 150000 ## equal to test len\n",
    "quake_counts = 16\n",
    "chunks_count = 4195 - quake_counts - 1 ## last chunk and quakes are discarded\n",
    "chunk_index = 0\n",
    "number_of_feature = int(chunk_len/resample_window_size)\n",
    "\n",
    "X_train = np.zeros([chunks_count, number_of_feature])\n",
    "y_train = np.zeros([chunks_count, 1])\n",
    "\n",
    "df_generator = pd.read_csv(f'{ROOT_PATH}/data/train.csv', chunksize=chunk_len)\n",
    "for df_chunk in df_generator:\n",
    "    if is_quake_in_chunk(df_chunk):\n",
    "        continue\n",
    "\n",
    "    df_chunk_resampled = df_chunk.reset_index(drop=True).groupby(by=lambda x: int(x/resample_window_size), axis=0).mean()\n",
    "    \n",
    "    if df_chunk_resampled.acoustic_data.values.shape[0] != number_of_feature:\n",
    "        continue\n",
    "    \n",
    "    X_train[chunk_index, :] = df_chunk_resampled.acoustic_data.values\n",
    "    y_train[chunk_index, 0] = np.mean(df_chunk_resampled.time_to_failure.values)\n",
    "    \n",
    "    chunk_index = chunk_index + 1\n",
    "    progress_bar(chunk_index, chunks_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4178, 10000)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4178, 1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tofile, X_test_tofile, y_train_tofile, y_test_tofile = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(f'{ROOT_PATH}/data/train_data.h5', \"w\") as out:\n",
    "    data_type = 'float64'\n",
    "    out.create_dataset(\"X_train\", data=X_train_tofile)\n",
    "    out.create_dataset(\"y_train\", data=y_train_tofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{ROOT_PATH}/data/test_data.h5', \"w\") as out:\n",
    "    data_type = 'float64'\n",
    "    out.create_dataset(\"X_test\", data=X_test_tofile)\n",
    "    out.create_dataset(\"y_test\", data=y_test_tofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
